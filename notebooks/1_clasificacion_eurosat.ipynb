{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea768d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Añade el path absoluto a la carpeta donde está el archivo\n",
    "sys.path.append(os.path.abspath(\"../MTP/Multi_Task_Pretrain/backbone\"))\n",
    "\n",
    "# Importa correctamente el modelo\n",
    "from vit_win_rvsa_v3_wsz7 import vit_b_rvsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c33c92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The relative_pos_embedding is used\n",
      "The relative_pos_embedding is used\n",
      "The relative_pos_embedding is used\n",
      "The relative_pos_embedding is used\n",
      "The relative_pos_embedding is used\n",
      "The relative_pos_embedding is used\n",
      "The relative_pos_embedding is used\n",
      "The relative_pos_embedding is used\n",
      "The relative_pos_embedding is used\n",
      "The relative_pos_embedding is used\n",
      "The relative_pos_embedding is used\n",
      "The relative_pos_embedding is used\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# === Agregar la ruta absoluta a la carpeta 'backbone' ===\n",
    "sys.path.append(os.path.abspath(\"../MTP/Multi_Task_Pretrain/backbone\"))\n",
    "\n",
    "from vit_win_rvsa_v3_wsz7 import vit_b_rvsa\n",
    "\n",
    "# === Paso 1: preparar argumentos para el backbone ===\n",
    "class Args:\n",
    "    image_size = 224\n",
    "    use_ckpt = \"False\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# === Paso 2: crear el backbone ===\n",
    "backbone = vit_b_rvsa(args, inchannels=3)\n",
    "\n",
    "# === Paso 3: definir modelo completo (backbone + clasificador) ===\n",
    "class ModeloClasificacion(nn.Module):\n",
    "    def __init__(self, backbone, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.classifier = nn.Linear(backbone.out_channels[0], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)[0]\n",
    "        pooled = nn.functional.adaptive_avg_pool2d(features, 1).view(x.size(0), -1)\n",
    "        return self.classifier(pooled)\n",
    "\n",
    "# === Paso 4: crear el modelo y enviarlo al dispositivo ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ModeloClasificacion(backbone, num_classes=10).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12404f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94.3M/94.3M [00:00<00:00, 114MB/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import EuroSAT\n",
    "\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "root_path = \"../data\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Tamaño esperado por ViT\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])  # Normalización de ImageNet\n",
    "])\n",
    "\n",
    "# Descargar el dataset\n",
    "dataset = EuroSAT(root=root_path, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1080d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# 80% train, 20% val\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3825e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb2cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] Step 10/675 - Loss: 2.0099\n",
      "[1/10] Step 20/675 - Loss: 1.8445\n",
      "[1/10] Step 20/675 - Loss: 1.8445\n",
      "[1/10] Step 30/675 - Loss: 1.6258\n",
      "[1/10] Step 30/675 - Loss: 1.6258\n",
      "[1/10] Step 40/675 - Loss: 1.6623\n",
      "[1/10] Step 40/675 - Loss: 1.6623\n",
      "[1/10] Step 50/675 - Loss: 1.7422\n",
      "[1/10] Step 50/675 - Loss: 1.7422\n",
      "[1/10] Step 60/675 - Loss: 1.6238\n",
      "[1/10] Step 60/675 - Loss: 1.6238\n",
      "[1/10] Step 70/675 - Loss: 1.3699\n",
      "[1/10] Step 70/675 - Loss: 1.3699\n",
      "[1/10] Step 80/675 - Loss: 1.2827\n",
      "[1/10] Step 80/675 - Loss: 1.2827\n",
      "[1/10] Step 90/675 - Loss: 1.6294\n",
      "[1/10] Step 90/675 - Loss: 1.6294\n",
      "[1/10] Step 100/675 - Loss: 1.5541\n",
      "[1/10] Step 100/675 - Loss: 1.5541\n",
      "[1/10] Step 110/675 - Loss: 1.4670\n",
      "[1/10] Step 110/675 - Loss: 1.4670\n",
      "[1/10] Step 120/675 - Loss: 1.3743\n",
      "[1/10] Step 120/675 - Loss: 1.3743\n",
      "[1/10] Step 130/675 - Loss: 1.5157\n",
      "[1/10] Step 130/675 - Loss: 1.5157\n",
      "[1/10] Step 140/675 - Loss: 1.3642\n",
      "[1/10] Step 140/675 - Loss: 1.3642\n",
      "[1/10] Step 150/675 - Loss: 1.1901\n",
      "[1/10] Step 150/675 - Loss: 1.1901\n",
      "[1/10] Step 160/675 - Loss: 1.3216\n",
      "[1/10] Step 160/675 - Loss: 1.3216\n",
      "[1/10] Step 170/675 - Loss: 1.2266\n",
      "[1/10] Step 170/675 - Loss: 1.2266\n",
      "[1/10] Step 180/675 - Loss: 1.3600\n",
      "[1/10] Step 180/675 - Loss: 1.3600\n",
      "[1/10] Step 190/675 - Loss: 1.3580\n",
      "[1/10] Step 190/675 - Loss: 1.3580\n",
      "[1/10] Step 200/675 - Loss: 1.4629\n",
      "[1/10] Step 200/675 - Loss: 1.4629\n",
      "[1/10] Step 210/675 - Loss: 1.4585\n",
      "[1/10] Step 210/675 - Loss: 1.4585\n",
      "[1/10] Step 220/675 - Loss: 0.9508\n",
      "[1/10] Step 220/675 - Loss: 0.9508\n",
      "[1/10] Step 230/675 - Loss: 0.7635\n",
      "[1/10] Step 230/675 - Loss: 0.7635\n",
      "[1/10] Step 240/675 - Loss: 1.0473\n",
      "[1/10] Step 240/675 - Loss: 1.0473\n",
      "[1/10] Step 250/675 - Loss: 1.1868\n",
      "[1/10] Step 250/675 - Loss: 1.1868\n",
      "[1/10] Step 260/675 - Loss: 0.7367\n",
      "[1/10] Step 260/675 - Loss: 0.7367\n",
      "[1/10] Step 270/675 - Loss: 1.2477\n",
      "[1/10] Step 270/675 - Loss: 1.2477\n",
      "[1/10] Step 280/675 - Loss: 1.3974\n",
      "[1/10] Step 280/675 - Loss: 1.3974\n",
      "[1/10] Step 290/675 - Loss: 1.6056\n",
      "[1/10] Step 290/675 - Loss: 1.6056\n",
      "[1/10] Step 300/675 - Loss: 1.4096\n",
      "[1/10] Step 300/675 - Loss: 1.4096\n",
      "[1/10] Step 310/675 - Loss: 1.0644\n",
      "[1/10] Step 310/675 - Loss: 1.0644\n",
      "[1/10] Step 320/675 - Loss: 0.7505\n",
      "[1/10] Step 320/675 - Loss: 0.7505\n",
      "[1/10] Step 330/675 - Loss: 1.1275\n",
      "[1/10] Step 330/675 - Loss: 1.1275\n",
      "[1/10] Step 340/675 - Loss: 0.7197\n",
      "[1/10] Step 340/675 - Loss: 0.7197\n",
      "[1/10] Step 350/675 - Loss: 0.9942\n",
      "[1/10] Step 350/675 - Loss: 0.9942\n",
      "[1/10] Step 360/675 - Loss: 1.1392\n",
      "[1/10] Step 360/675 - Loss: 1.1392\n",
      "[1/10] Step 370/675 - Loss: 0.8091\n",
      "[1/10] Step 370/675 - Loss: 0.8091\n",
      "[1/10] Step 380/675 - Loss: 1.3154\n",
      "[1/10] Step 380/675 - Loss: 1.3154\n",
      "[1/10] Step 390/675 - Loss: 0.7907\n",
      "[1/10] Step 390/675 - Loss: 0.7907\n",
      "[1/10] Step 400/675 - Loss: 1.0644\n",
      "[1/10] Step 400/675 - Loss: 1.0644\n",
      "[1/10] Step 410/675 - Loss: 1.4052\n",
      "[1/10] Step 410/675 - Loss: 1.4052\n",
      "[1/10] Step 420/675 - Loss: 1.1447\n",
      "[1/10] Step 420/675 - Loss: 1.1447\n",
      "[1/10] Step 430/675 - Loss: 0.9582\n",
      "[1/10] Step 430/675 - Loss: 0.9582\n",
      "[1/10] Step 440/675 - Loss: 0.9868\n",
      "[1/10] Step 440/675 - Loss: 0.9868\n",
      "[1/10] Step 450/675 - Loss: 0.8184\n",
      "[1/10] Step 450/675 - Loss: 0.8184\n",
      "[1/10] Step 460/675 - Loss: 0.9606\n",
      "[1/10] Step 460/675 - Loss: 0.9606\n",
      "[1/10] Step 470/675 - Loss: 0.7938\n",
      "[1/10] Step 470/675 - Loss: 0.7938\n",
      "[1/10] Step 480/675 - Loss: 1.0681\n",
      "[1/10] Step 480/675 - Loss: 1.0681\n",
      "[1/10] Step 490/675 - Loss: 0.8120\n",
      "[1/10] Step 490/675 - Loss: 0.8120\n",
      "[1/10] Step 500/675 - Loss: 0.9874\n",
      "[1/10] Step 500/675 - Loss: 0.9874\n",
      "[1/10] Step 510/675 - Loss: 0.8054\n",
      "[1/10] Step 510/675 - Loss: 0.8054\n",
      "[1/10] Step 520/675 - Loss: 0.9780\n",
      "[1/10] Step 520/675 - Loss: 0.9780\n",
      "[1/10] Step 530/675 - Loss: 1.1036\n",
      "[1/10] Step 530/675 - Loss: 1.1036\n",
      "[1/10] Step 540/675 - Loss: 0.7107\n",
      "[1/10] Step 540/675 - Loss: 0.7107\n",
      "[1/10] Step 550/675 - Loss: 0.6956\n",
      "[1/10] Step 550/675 - Loss: 0.6956\n",
      "[1/10] Step 560/675 - Loss: 1.0756\n",
      "[1/10] Step 560/675 - Loss: 1.0756\n",
      "[1/10] Step 570/675 - Loss: 0.9877\n",
      "[1/10] Step 570/675 - Loss: 0.9877\n",
      "[1/10] Step 580/675 - Loss: 0.8565\n",
      "[1/10] Step 580/675 - Loss: 0.8565\n",
      "[1/10] Step 590/675 - Loss: 1.2428\n",
      "[1/10] Step 590/675 - Loss: 1.2428\n",
      "[1/10] Step 600/675 - Loss: 0.9081\n",
      "[1/10] Step 600/675 - Loss: 0.9081\n",
      "[1/10] Step 610/675 - Loss: 0.7746\n",
      "[1/10] Step 610/675 - Loss: 0.7746\n",
      "[1/10] Step 620/675 - Loss: 0.8446\n",
      "[1/10] Step 620/675 - Loss: 0.8446\n",
      "[1/10] Step 630/675 - Loss: 0.9514\n",
      "[1/10] Step 630/675 - Loss: 0.9514\n",
      "[1/10] Step 640/675 - Loss: 1.1716\n",
      "[1/10] Step 640/675 - Loss: 1.1716\n",
      "[1/10] Step 650/675 - Loss: 0.5782\n",
      "[1/10] Step 650/675 - Loss: 0.5782\n",
      "[1/10] Step 660/675 - Loss: 0.7232\n",
      "[1/10] Step 660/675 - Loss: 0.7232\n",
      "[1/10] Step 670/675 - Loss: 0.6661\n",
      "[1/10] Step 670/675 - Loss: 0.6661\n",
      "[1/10] Step 675/675 - Loss: 0.9611\n",
      "[1/10] Step 675/675 - Loss: 0.9611\n",
      "Época 1 finalizada | Loss: 1.1442 | Acc: 57.94% | Tiempo: 128.6s\n",
      "Época 1 finalizada | Loss: 1.1442 | Acc: 57.94% | Tiempo: 128.6s\n",
      "Validación - Acc: 64.56%\n",
      "------------------------------------------------------------\n",
      "Validación - Acc: 64.56%\n",
      "------------------------------------------------------------\n",
      "Nuevo mejor modelo guardado con Acc: 64.56%\n",
      "Nuevo mejor modelo guardado con Acc: 64.56%\n",
      "[2/10] Step 10/675 - Loss: 0.8954\n",
      "[2/10] Step 10/675 - Loss: 0.8954\n",
      "[2/10] Step 20/675 - Loss: 1.1778\n",
      "[2/10] Step 20/675 - Loss: 1.1778\n",
      "[2/10] Step 30/675 - Loss: 0.8084\n",
      "[2/10] Step 30/675 - Loss: 0.8084\n",
      "[2/10] Step 40/675 - Loss: 0.9575\n",
      "[2/10] Step 40/675 - Loss: 0.9575\n",
      "[2/10] Step 50/675 - Loss: 1.4689\n",
      "[2/10] Step 50/675 - Loss: 1.4689\n",
      "[2/10] Step 60/675 - Loss: 1.0963\n",
      "[2/10] Step 60/675 - Loss: 1.0963\n",
      "[2/10] Step 70/675 - Loss: 0.7235\n",
      "[2/10] Step 70/675 - Loss: 0.7235\n",
      "[2/10] Step 80/675 - Loss: 0.9826\n",
      "[2/10] Step 80/675 - Loss: 0.9826\n",
      "[2/10] Step 90/675 - Loss: 0.7692\n",
      "[2/10] Step 90/675 - Loss: 0.7692\n",
      "[2/10] Step 100/675 - Loss: 0.8891\n",
      "[2/10] Step 100/675 - Loss: 0.8891\n",
      "[2/10] Step 110/675 - Loss: 0.8810\n",
      "[2/10] Step 110/675 - Loss: 0.8810\n",
      "[2/10] Step 120/675 - Loss: 0.9790\n",
      "[2/10] Step 120/675 - Loss: 0.9790\n",
      "[2/10] Step 130/675 - Loss: 0.9196\n",
      "[2/10] Step 130/675 - Loss: 0.9196\n",
      "[2/10] Step 140/675 - Loss: 0.7445\n",
      "[2/10] Step 140/675 - Loss: 0.7445\n",
      "[2/10] Step 150/675 - Loss: 0.9730\n",
      "[2/10] Step 150/675 - Loss: 0.9730\n",
      "[2/10] Step 160/675 - Loss: 1.1967\n",
      "[2/10] Step 160/675 - Loss: 1.1967\n",
      "[2/10] Step 170/675 - Loss: 0.7670\n",
      "[2/10] Step 170/675 - Loss: 0.7670\n",
      "[2/10] Step 180/675 - Loss: 0.4892\n",
      "[2/10] Step 180/675 - Loss: 0.4892\n",
      "[2/10] Step 190/675 - Loss: 1.0251\n",
      "[2/10] Step 190/675 - Loss: 1.0251\n",
      "[2/10] Step 200/675 - Loss: 1.0571\n",
      "[2/10] Step 200/675 - Loss: 1.0571\n",
      "[2/10] Step 210/675 - Loss: 0.7559\n",
      "[2/10] Step 210/675 - Loss: 0.7559\n",
      "[2/10] Step 220/675 - Loss: 0.5150\n",
      "[2/10] Step 220/675 - Loss: 0.5150\n",
      "[2/10] Step 230/675 - Loss: 0.7058\n",
      "[2/10] Step 230/675 - Loss: 0.7058\n",
      "[2/10] Step 240/675 - Loss: 1.0010\n",
      "[2/10] Step 240/675 - Loss: 1.0010\n",
      "[2/10] Step 250/675 - Loss: 0.9492\n",
      "[2/10] Step 250/675 - Loss: 0.9492\n",
      "[2/10] Step 260/675 - Loss: 0.5090\n",
      "[2/10] Step 260/675 - Loss: 0.5090\n",
      "[2/10] Step 270/675 - Loss: 0.7739\n",
      "[2/10] Step 270/675 - Loss: 0.7739\n",
      "[2/10] Step 280/675 - Loss: 0.7732\n",
      "[2/10] Step 280/675 - Loss: 0.7732\n",
      "[2/10] Step 290/675 - Loss: 0.7511\n",
      "[2/10] Step 290/675 - Loss: 0.7511\n",
      "[2/10] Step 300/675 - Loss: 0.7848\n",
      "[2/10] Step 300/675 - Loss: 0.7848\n",
      "[2/10] Step 310/675 - Loss: 0.8106\n",
      "[2/10] Step 310/675 - Loss: 0.8106\n",
      "[2/10] Step 320/675 - Loss: 1.4090\n",
      "[2/10] Step 320/675 - Loss: 1.4090\n",
      "[2/10] Step 330/675 - Loss: 0.7976\n",
      "[2/10] Step 330/675 - Loss: 0.7976\n",
      "[2/10] Step 340/675 - Loss: 1.0124\n",
      "[2/10] Step 340/675 - Loss: 1.0124\n",
      "[2/10] Step 350/675 - Loss: 0.9231\n",
      "[2/10] Step 350/675 - Loss: 0.9231\n",
      "[2/10] Step 360/675 - Loss: 0.5364\n",
      "[2/10] Step 360/675 - Loss: 0.5364\n",
      "[2/10] Step 370/675 - Loss: 0.5694\n",
      "[2/10] Step 370/675 - Loss: 0.5694\n",
      "[2/10] Step 380/675 - Loss: 0.7933\n",
      "[2/10] Step 380/675 - Loss: 0.7933\n",
      "[2/10] Step 390/675 - Loss: 0.5373\n",
      "[2/10] Step 390/675 - Loss: 0.5373\n",
      "[2/10] Step 400/675 - Loss: 0.8196\n",
      "[2/10] Step 400/675 - Loss: 0.8196\n",
      "[2/10] Step 410/675 - Loss: 0.9098\n",
      "[2/10] Step 410/675 - Loss: 0.9098\n",
      "[2/10] Step 420/675 - Loss: 0.9914\n",
      "[2/10] Step 420/675 - Loss: 0.9914\n",
      "[2/10] Step 430/675 - Loss: 0.8823\n",
      "[2/10] Step 430/675 - Loss: 0.8823\n",
      "[2/10] Step 440/675 - Loss: 0.6763\n",
      "[2/10] Step 440/675 - Loss: 0.6763\n",
      "[2/10] Step 450/675 - Loss: 0.6475\n",
      "[2/10] Step 450/675 - Loss: 0.6475\n",
      "[2/10] Step 460/675 - Loss: 0.6743\n",
      "[2/10] Step 460/675 - Loss: 0.6743\n",
      "[2/10] Step 470/675 - Loss: 0.6044\n",
      "[2/10] Step 470/675 - Loss: 0.6044\n",
      "[2/10] Step 480/675 - Loss: 0.8032\n",
      "[2/10] Step 480/675 - Loss: 0.8032\n",
      "[2/10] Step 490/675 - Loss: 0.7799\n",
      "[2/10] Step 490/675 - Loss: 0.7799\n",
      "[2/10] Step 500/675 - Loss: 0.8733\n",
      "[2/10] Step 500/675 - Loss: 0.8733\n",
      "[2/10] Step 510/675 - Loss: 0.9543\n",
      "[2/10] Step 510/675 - Loss: 0.9543\n",
      "[2/10] Step 520/675 - Loss: 0.7045\n",
      "[2/10] Step 520/675 - Loss: 0.7045\n",
      "[2/10] Step 530/675 - Loss: 0.9098\n",
      "[2/10] Step 530/675 - Loss: 0.9098\n",
      "[2/10] Step 540/675 - Loss: 0.5006\n",
      "[2/10] Step 540/675 - Loss: 0.5006\n",
      "[2/10] Step 550/675 - Loss: 0.8309\n",
      "[2/10] Step 550/675 - Loss: 0.8309\n",
      "[2/10] Step 560/675 - Loss: 1.1970\n",
      "[2/10] Step 560/675 - Loss: 1.1970\n",
      "[2/10] Step 570/675 - Loss: 0.7512\n",
      "[2/10] Step 570/675 - Loss: 0.7512\n",
      "[2/10] Step 580/675 - Loss: 0.8609\n",
      "[2/10] Step 580/675 - Loss: 0.8609\n",
      "[2/10] Step 590/675 - Loss: 0.4906\n",
      "[2/10] Step 590/675 - Loss: 0.4906\n",
      "[2/10] Step 600/675 - Loss: 0.6425\n",
      "[2/10] Step 600/675 - Loss: 0.6425\n",
      "[2/10] Step 610/675 - Loss: 0.7234\n",
      "[2/10] Step 610/675 - Loss: 0.7234\n",
      "[2/10] Step 620/675 - Loss: 0.7434\n",
      "[2/10] Step 620/675 - Loss: 0.7434\n",
      "[2/10] Step 630/675 - Loss: 0.4696\n",
      "[2/10] Step 630/675 - Loss: 0.4696\n",
      "[2/10] Step 640/675 - Loss: 0.4737\n",
      "[2/10] Step 640/675 - Loss: 0.4737\n",
      "[2/10] Step 650/675 - Loss: 1.0346\n",
      "[2/10] Step 650/675 - Loss: 1.0346\n",
      "[2/10] Step 660/675 - Loss: 0.7252\n",
      "[2/10] Step 660/675 - Loss: 0.7252\n",
      "[2/10] Step 670/675 - Loss: 0.8384\n",
      "[2/10] Step 670/675 - Loss: 0.8384\n",
      "[2/10] Step 675/675 - Loss: 0.9836\n",
      "[2/10] Step 675/675 - Loss: 0.9836\n",
      "Época 2 finalizada | Loss: 0.8069 | Acc: 71.43% | Tiempo: 129.0s\n",
      "Época 2 finalizada | Loss: 0.8069 | Acc: 71.43% | Tiempo: 129.0s\n",
      "Validación - Acc: 73.57%\n",
      "------------------------------------------------------------\n",
      "Validación - Acc: 73.57%\n",
      "------------------------------------------------------------\n",
      "Nuevo mejor modelo guardado con Acc: 73.57%\n",
      "Nuevo mejor modelo guardado con Acc: 73.57%\n",
      "[3/10] Step 10/675 - Loss: 0.8337\n",
      "[3/10] Step 10/675 - Loss: 0.8337\n",
      "[3/10] Step 20/675 - Loss: 1.0420\n",
      "[3/10] Step 20/675 - Loss: 1.0420\n",
      "[3/10] Step 30/675 - Loss: 0.5843\n",
      "[3/10] Step 30/675 - Loss: 0.5843\n",
      "[3/10] Step 40/675 - Loss: 0.5415\n",
      "[3/10] Step 40/675 - Loss: 0.5415\n",
      "[3/10] Step 50/675 - Loss: 0.5578\n",
      "[3/10] Step 50/675 - Loss: 0.5578\n",
      "[3/10] Step 60/675 - Loss: 0.6211\n",
      "[3/10] Step 60/675 - Loss: 0.6211\n",
      "[3/10] Step 70/675 - Loss: 0.4841\n",
      "[3/10] Step 70/675 - Loss: 0.4841\n",
      "[3/10] Step 80/675 - Loss: 0.5746\n",
      "[3/10] Step 80/675 - Loss: 0.5746\n",
      "[3/10] Step 90/675 - Loss: 0.5265\n",
      "[3/10] Step 90/675 - Loss: 0.5265\n",
      "[3/10] Step 100/675 - Loss: 0.3994\n",
      "[3/10] Step 100/675 - Loss: 0.3994\n",
      "[3/10] Step 110/675 - Loss: 0.9343\n",
      "[3/10] Step 110/675 - Loss: 0.9343\n",
      "[3/10] Step 120/675 - Loss: 1.0100\n",
      "[3/10] Step 120/675 - Loss: 1.0100\n",
      "[3/10] Step 130/675 - Loss: 0.7711\n",
      "[3/10] Step 130/675 - Loss: 0.7711\n",
      "[3/10] Step 140/675 - Loss: 0.6626\n",
      "[3/10] Step 140/675 - Loss: 0.6626\n",
      "[3/10] Step 150/675 - Loss: 0.6199\n",
      "[3/10] Step 150/675 - Loss: 0.6199\n",
      "[3/10] Step 160/675 - Loss: 0.6577\n",
      "[3/10] Step 160/675 - Loss: 0.6577\n",
      "[3/10] Step 170/675 - Loss: 0.9883\n",
      "[3/10] Step 170/675 - Loss: 0.9883\n",
      "[3/10] Step 180/675 - Loss: 0.5631\n",
      "[3/10] Step 180/675 - Loss: 0.5631\n",
      "[3/10] Step 190/675 - Loss: 0.8731\n",
      "[3/10] Step 190/675 - Loss: 0.8731\n",
      "[3/10] Step 200/675 - Loss: 0.7626\n",
      "[3/10] Step 200/675 - Loss: 0.7626\n",
      "[3/10] Step 210/675 - Loss: 0.7200\n",
      "[3/10] Step 210/675 - Loss: 0.7200\n",
      "[3/10] Step 220/675 - Loss: 0.4841\n",
      "[3/10] Step 220/675 - Loss: 0.4841\n",
      "[3/10] Step 230/675 - Loss: 0.7263\n",
      "[3/10] Step 230/675 - Loss: 0.7263\n",
      "[3/10] Step 240/675 - Loss: 0.7076\n",
      "[3/10] Step 240/675 - Loss: 0.7076\n",
      "[3/10] Step 250/675 - Loss: 0.7385\n",
      "[3/10] Step 250/675 - Loss: 0.7385\n",
      "[3/10] Step 260/675 - Loss: 0.6493\n",
      "[3/10] Step 260/675 - Loss: 0.6493\n",
      "[3/10] Step 270/675 - Loss: 0.6597\n",
      "[3/10] Step 270/675 - Loss: 0.6597\n",
      "[3/10] Step 280/675 - Loss: 0.6304\n",
      "[3/10] Step 280/675 - Loss: 0.6304\n",
      "[3/10] Step 290/675 - Loss: 0.5280\n",
      "[3/10] Step 290/675 - Loss: 0.5280\n",
      "[3/10] Step 300/675 - Loss: 0.5889\n",
      "[3/10] Step 300/675 - Loss: 0.5889\n",
      "[3/10] Step 310/675 - Loss: 0.5517\n",
      "[3/10] Step 310/675 - Loss: 0.5517\n",
      "[3/10] Step 320/675 - Loss: 0.7017\n",
      "[3/10] Step 320/675 - Loss: 0.7017\n",
      "[3/10] Step 330/675 - Loss: 0.6799\n",
      "[3/10] Step 330/675 - Loss: 0.6799\n",
      "[3/10] Step 340/675 - Loss: 0.5184\n",
      "[3/10] Step 340/675 - Loss: 0.5184\n",
      "[3/10] Step 350/675 - Loss: 0.7004\n",
      "[3/10] Step 350/675 - Loss: 0.7004\n",
      "[3/10] Step 360/675 - Loss: 0.6098\n",
      "[3/10] Step 360/675 - Loss: 0.6098\n",
      "[3/10] Step 370/675 - Loss: 0.5538\n",
      "[3/10] Step 370/675 - Loss: 0.5538\n",
      "[3/10] Step 380/675 - Loss: 0.7078\n",
      "[3/10] Step 380/675 - Loss: 0.7078\n",
      "[3/10] Step 390/675 - Loss: 0.7192\n",
      "[3/10] Step 390/675 - Loss: 0.7192\n",
      "[3/10] Step 400/675 - Loss: 0.4504\n",
      "[3/10] Step 400/675 - Loss: 0.4504\n",
      "[3/10] Step 410/675 - Loss: 0.5294\n",
      "[3/10] Step 410/675 - Loss: 0.5294\n",
      "[3/10] Step 420/675 - Loss: 0.5468\n",
      "[3/10] Step 420/675 - Loss: 0.5468\n",
      "[3/10] Step 430/675 - Loss: 0.4834\n",
      "[3/10] Step 430/675 - Loss: 0.4834\n",
      "[3/10] Step 440/675 - Loss: 0.6575\n",
      "[3/10] Step 440/675 - Loss: 0.6575\n",
      "[3/10] Step 450/675 - Loss: 0.6642\n",
      "[3/10] Step 450/675 - Loss: 0.6642\n",
      "[3/10] Step 460/675 - Loss: 0.7543\n",
      "[3/10] Step 460/675 - Loss: 0.7543\n",
      "[3/10] Step 470/675 - Loss: 0.8382\n",
      "[3/10] Step 470/675 - Loss: 0.8382\n",
      "[3/10] Step 480/675 - Loss: 0.7787\n",
      "[3/10] Step 480/675 - Loss: 0.7787\n",
      "[3/10] Step 490/675 - Loss: 0.7089\n",
      "[3/10] Step 490/675 - Loss: 0.7089\n",
      "[3/10] Step 500/675 - Loss: 0.6110\n",
      "[3/10] Step 500/675 - Loss: 0.6110\n",
      "[3/10] Step 510/675 - Loss: 0.4174\n",
      "[3/10] Step 510/675 - Loss: 0.4174\n",
      "[3/10] Step 520/675 - Loss: 1.2466\n",
      "[3/10] Step 520/675 - Loss: 1.2466\n",
      "[3/10] Step 530/675 - Loss: 0.7085\n",
      "[3/10] Step 530/675 - Loss: 0.7085\n",
      "[3/10] Step 540/675 - Loss: 0.4196\n",
      "[3/10] Step 540/675 - Loss: 0.4196\n",
      "[3/10] Step 550/675 - Loss: 0.3678\n",
      "[3/10] Step 550/675 - Loss: 0.3678\n",
      "[3/10] Step 560/675 - Loss: 0.4155\n",
      "[3/10] Step 560/675 - Loss: 0.4155\n",
      "[3/10] Step 570/675 - Loss: 0.5035\n",
      "[3/10] Step 570/675 - Loss: 0.5035\n",
      "[3/10] Step 580/675 - Loss: 0.4626\n",
      "[3/10] Step 580/675 - Loss: 0.4626\n",
      "[3/10] Step 590/675 - Loss: 0.5872\n",
      "[3/10] Step 590/675 - Loss: 0.5872\n",
      "[3/10] Step 600/675 - Loss: 0.6321\n",
      "[3/10] Step 600/675 - Loss: 0.6321\n",
      "[3/10] Step 610/675 - Loss: 0.3268\n",
      "[3/10] Step 610/675 - Loss: 0.3268\n",
      "[3/10] Step 620/675 - Loss: 0.5801\n",
      "[3/10] Step 620/675 - Loss: 0.5801\n",
      "[3/10] Step 630/675 - Loss: 0.7367\n",
      "[3/10] Step 630/675 - Loss: 0.7367\n",
      "[3/10] Step 640/675 - Loss: 0.5789\n",
      "[3/10] Step 640/675 - Loss: 0.5789\n",
      "[3/10] Step 650/675 - Loss: 0.6490\n",
      "[3/10] Step 650/675 - Loss: 0.6490\n",
      "[3/10] Step 660/675 - Loss: 0.6409\n",
      "[3/10] Step 660/675 - Loss: 0.6409\n",
      "[3/10] Step 670/675 - Loss: 0.5734\n",
      "[3/10] Step 670/675 - Loss: 0.5734\n",
      "[3/10] Step 675/675 - Loss: 0.4941\n",
      "[3/10] Step 675/675 - Loss: 0.4941\n",
      "Época 3 finalizada | Loss: 0.6853 | Acc: 75.95% | Tiempo: 129.4s\n",
      "Época 3 finalizada | Loss: 0.6853 | Acc: 75.95% | Tiempo: 129.4s\n",
      "Validación - Acc: 77.69%\n",
      "------------------------------------------------------------\n",
      "Validación - Acc: 77.69%\n",
      "------------------------------------------------------------\n",
      "Nuevo mejor modelo guardado con Acc: 77.69%\n",
      "Nuevo mejor modelo guardado con Acc: 77.69%\n",
      "[4/10] Step 10/675 - Loss: 1.3777\n",
      "[4/10] Step 10/675 - Loss: 1.3777\n",
      "[4/10] Step 20/675 - Loss: 0.8785\n",
      "[4/10] Step 20/675 - Loss: 0.8785\n",
      "[4/10] Step 30/675 - Loss: 0.4527\n",
      "[4/10] Step 30/675 - Loss: 0.4527\n",
      "[4/10] Step 40/675 - Loss: 0.5621\n",
      "[4/10] Step 40/675 - Loss: 0.5621\n",
      "[4/10] Step 50/675 - Loss: 0.6739\n",
      "[4/10] Step 50/675 - Loss: 0.6739\n",
      "[4/10] Step 60/675 - Loss: 0.4002\n",
      "[4/10] Step 60/675 - Loss: 0.4002\n",
      "[4/10] Step 70/675 - Loss: 0.5432\n",
      "[4/10] Step 70/675 - Loss: 0.5432\n",
      "[4/10] Step 80/675 - Loss: 0.4966\n",
      "[4/10] Step 80/675 - Loss: 0.4966\n",
      "[4/10] Step 90/675 - Loss: 1.0622\n",
      "[4/10] Step 90/675 - Loss: 1.0622\n",
      "[4/10] Step 100/675 - Loss: 0.3931\n",
      "[4/10] Step 100/675 - Loss: 0.3931\n",
      "[4/10] Step 110/675 - Loss: 0.4966\n",
      "[4/10] Step 110/675 - Loss: 0.4966\n",
      "[4/10] Step 120/675 - Loss: 0.5581\n",
      "[4/10] Step 120/675 - Loss: 0.5581\n",
      "[4/10] Step 130/675 - Loss: 0.8017\n",
      "[4/10] Step 130/675 - Loss: 0.8017\n",
      "[4/10] Step 140/675 - Loss: 0.9353\n",
      "[4/10] Step 140/675 - Loss: 0.9353\n",
      "[4/10] Step 150/675 - Loss: 0.8164\n",
      "[4/10] Step 150/675 - Loss: 0.8164\n",
      "[4/10] Step 160/675 - Loss: 0.7535\n",
      "[4/10] Step 160/675 - Loss: 0.7535\n",
      "[4/10] Step 170/675 - Loss: 0.5072\n",
      "[4/10] Step 170/675 - Loss: 0.5072\n",
      "[4/10] Step 180/675 - Loss: 0.7290\n",
      "[4/10] Step 180/675 - Loss: 0.7290\n",
      "[4/10] Step 190/675 - Loss: 0.5489\n",
      "[4/10] Step 190/675 - Loss: 0.5489\n",
      "[4/10] Step 200/675 - Loss: 0.9703\n",
      "[4/10] Step 200/675 - Loss: 0.9703\n",
      "[4/10] Step 210/675 - Loss: 0.7611\n",
      "[4/10] Step 210/675 - Loss: 0.7611\n",
      "[4/10] Step 220/675 - Loss: 0.4974\n",
      "[4/10] Step 220/675 - Loss: 0.4974\n",
      "[4/10] Step 230/675 - Loss: 0.6692\n",
      "[4/10] Step 230/675 - Loss: 0.6692\n",
      "[4/10] Step 240/675 - Loss: 0.7128\n",
      "[4/10] Step 240/675 - Loss: 0.7128\n",
      "[4/10] Step 250/675 - Loss: 0.8060\n",
      "[4/10] Step 250/675 - Loss: 0.8060\n",
      "[4/10] Step 260/675 - Loss: 1.2773\n",
      "[4/10] Step 260/675 - Loss: 1.2773\n",
      "[4/10] Step 270/675 - Loss: 0.7239\n",
      "[4/10] Step 270/675 - Loss: 0.7239\n",
      "[4/10] Step 280/675 - Loss: 0.5326\n",
      "[4/10] Step 280/675 - Loss: 0.5326\n",
      "[4/10] Step 290/675 - Loss: 0.5474\n",
      "[4/10] Step 290/675 - Loss: 0.5474\n",
      "[4/10] Step 300/675 - Loss: 0.5327\n",
      "[4/10] Step 300/675 - Loss: 0.5327\n",
      "[4/10] Step 310/675 - Loss: 0.5355\n",
      "[4/10] Step 310/675 - Loss: 0.5355\n",
      "[4/10] Step 320/675 - Loss: 0.2540\n",
      "[4/10] Step 320/675 - Loss: 0.2540\n",
      "[4/10] Step 330/675 - Loss: 0.2710\n",
      "[4/10] Step 330/675 - Loss: 0.2710\n",
      "[4/10] Step 340/675 - Loss: 0.5836\n",
      "[4/10] Step 340/675 - Loss: 0.5836\n",
      "[4/10] Step 350/675 - Loss: 0.9098\n",
      "[4/10] Step 350/675 - Loss: 0.9098\n",
      "[4/10] Step 360/675 - Loss: 0.7999\n",
      "[4/10] Step 360/675 - Loss: 0.7999\n",
      "[4/10] Step 370/675 - Loss: 0.7438\n",
      "[4/10] Step 370/675 - Loss: 0.7438\n",
      "[4/10] Step 380/675 - Loss: 0.7251\n",
      "[4/10] Step 380/675 - Loss: 0.7251\n",
      "[4/10] Step 390/675 - Loss: 0.7638\n",
      "[4/10] Step 390/675 - Loss: 0.7638\n",
      "[4/10] Step 400/675 - Loss: 0.7181\n",
      "[4/10] Step 400/675 - Loss: 0.7181\n",
      "[4/10] Step 410/675 - Loss: 0.7933\n",
      "[4/10] Step 410/675 - Loss: 0.7933\n",
      "[4/10] Step 420/675 - Loss: 0.6595\n",
      "[4/10] Step 420/675 - Loss: 0.6595\n",
      "[4/10] Step 430/675 - Loss: 0.3984\n",
      "[4/10] Step 430/675 - Loss: 0.3984\n",
      "[4/10] Step 440/675 - Loss: 0.6817\n",
      "[4/10] Step 440/675 - Loss: 0.6817\n",
      "[4/10] Step 450/675 - Loss: 0.6067\n",
      "[4/10] Step 450/675 - Loss: 0.6067\n",
      "[4/10] Step 460/675 - Loss: 0.5033\n",
      "[4/10] Step 460/675 - Loss: 0.5033\n",
      "[4/10] Step 470/675 - Loss: 0.6138\n",
      "[4/10] Step 470/675 - Loss: 0.6138\n",
      "[4/10] Step 480/675 - Loss: 0.4557\n",
      "[4/10] Step 480/675 - Loss: 0.4557\n",
      "[4/10] Step 490/675 - Loss: 0.3987\n",
      "[4/10] Step 490/675 - Loss: 0.3987\n",
      "[4/10] Step 500/675 - Loss: 0.6206\n",
      "[4/10] Step 500/675 - Loss: 0.6206\n",
      "[4/10] Step 510/675 - Loss: 0.5909\n",
      "[4/10] Step 510/675 - Loss: 0.5909\n",
      "[4/10] Step 520/675 - Loss: 0.6312\n",
      "[4/10] Step 520/675 - Loss: 0.6312\n",
      "[4/10] Step 530/675 - Loss: 0.4820\n",
      "[4/10] Step 530/675 - Loss: 0.4820\n",
      "[4/10] Step 540/675 - Loss: 0.7057\n",
      "[4/10] Step 540/675 - Loss: 0.7057\n",
      "[4/10] Step 550/675 - Loss: 0.7501\n",
      "[4/10] Step 550/675 - Loss: 0.7501\n",
      "[4/10] Step 560/675 - Loss: 0.7398\n",
      "[4/10] Step 560/675 - Loss: 0.7398\n",
      "[4/10] Step 570/675 - Loss: 0.6635\n",
      "[4/10] Step 570/675 - Loss: 0.6635\n",
      "[4/10] Step 580/675 - Loss: 0.3720\n",
      "[4/10] Step 580/675 - Loss: 0.3720\n",
      "[4/10] Step 590/675 - Loss: 0.4649\n",
      "[4/10] Step 590/675 - Loss: 0.4649\n",
      "[4/10] Step 600/675 - Loss: 0.5991\n",
      "[4/10] Step 600/675 - Loss: 0.5991\n",
      "[4/10] Step 610/675 - Loss: 0.3819\n",
      "[4/10] Step 610/675 - Loss: 0.3819\n",
      "[4/10] Step 620/675 - Loss: 0.3020\n",
      "[4/10] Step 620/675 - Loss: 0.3020\n",
      "[4/10] Step 630/675 - Loss: 0.6626\n",
      "[4/10] Step 630/675 - Loss: 0.6626\n",
      "[4/10] Step 640/675 - Loss: 0.4430\n",
      "[4/10] Step 640/675 - Loss: 0.4430\n",
      "[4/10] Step 650/675 - Loss: 1.0810\n",
      "[4/10] Step 650/675 - Loss: 1.0810\n",
      "[4/10] Step 660/675 - Loss: 0.6224\n",
      "[4/10] Step 660/675 - Loss: 0.6224\n",
      "[4/10] Step 670/675 - Loss: 0.4749\n",
      "[4/10] Step 670/675 - Loss: 0.4749\n",
      "[4/10] Step 675/675 - Loss: 0.4817\n",
      "[4/10] Step 675/675 - Loss: 0.4817\n",
      "Época 4 finalizada | Loss: 0.6047 | Acc: 78.75% | Tiempo: 129.0s\n",
      "Época 4 finalizada | Loss: 0.6047 | Acc: 78.75% | Tiempo: 129.0s\n",
      "Validación - Acc: 82.33%\n",
      "------------------------------------------------------------\n",
      "Validación - Acc: 82.33%\n",
      "------------------------------------------------------------\n",
      "Nuevo mejor modelo guardado con Acc: 82.33%\n",
      "Nuevo mejor modelo guardado con Acc: 82.33%\n",
      "[5/10] Step 10/675 - Loss: 0.5741\n",
      "[5/10] Step 10/675 - Loss: 0.5741\n",
      "[5/10] Step 20/675 - Loss: 0.6861\n",
      "[5/10] Step 20/675 - Loss: 0.6861\n",
      "[5/10] Step 30/675 - Loss: 0.4259\n",
      "[5/10] Step 30/675 - Loss: 0.4259\n",
      "[5/10] Step 40/675 - Loss: 0.5253\n",
      "[5/10] Step 40/675 - Loss: 0.5253\n",
      "[5/10] Step 50/675 - Loss: 0.4417\n",
      "[5/10] Step 50/675 - Loss: 0.4417\n",
      "[5/10] Step 60/675 - Loss: 0.6091\n",
      "[5/10] Step 60/675 - Loss: 0.6091\n",
      "[5/10] Step 70/675 - Loss: 0.8283\n",
      "[5/10] Step 70/675 - Loss: 0.8283\n",
      "[5/10] Step 80/675 - Loss: 0.5333\n",
      "[5/10] Step 80/675 - Loss: 0.5333\n",
      "[5/10] Step 90/675 - Loss: 0.6014\n",
      "[5/10] Step 90/675 - Loss: 0.6014\n",
      "[5/10] Step 100/675 - Loss: 0.6694\n",
      "[5/10] Step 100/675 - Loss: 0.6694\n",
      "[5/10] Step 110/675 - Loss: 0.4545\n",
      "[5/10] Step 110/675 - Loss: 0.4545\n",
      "[5/10] Step 120/675 - Loss: 0.3597\n",
      "[5/10] Step 120/675 - Loss: 0.3597\n",
      "[5/10] Step 130/675 - Loss: 0.5492\n",
      "[5/10] Step 130/675 - Loss: 0.5492\n",
      "[5/10] Step 140/675 - Loss: 0.3837\n",
      "[5/10] Step 140/675 - Loss: 0.3837\n",
      "[5/10] Step 150/675 - Loss: 0.3827\n",
      "[5/10] Step 150/675 - Loss: 0.3827\n",
      "[5/10] Step 160/675 - Loss: 0.3622\n",
      "[5/10] Step 160/675 - Loss: 0.3622\n",
      "[5/10] Step 170/675 - Loss: 0.4130\n",
      "[5/10] Step 170/675 - Loss: 0.4130\n",
      "[5/10] Step 180/675 - Loss: 0.5401\n",
      "[5/10] Step 180/675 - Loss: 0.5401\n",
      "[5/10] Step 190/675 - Loss: 0.8883\n",
      "[5/10] Step 190/675 - Loss: 0.8883\n",
      "[5/10] Step 200/675 - Loss: 0.8225\n",
      "[5/10] Step 200/675 - Loss: 0.8225\n",
      "[5/10] Step 210/675 - Loss: 0.9965\n",
      "[5/10] Step 210/675 - Loss: 0.9965\n",
      "[5/10] Step 220/675 - Loss: 0.4991\n",
      "[5/10] Step 220/675 - Loss: 0.4991\n",
      "[5/10] Step 230/675 - Loss: 0.4781\n",
      "[5/10] Step 230/675 - Loss: 0.4781\n",
      "[5/10] Step 240/675 - Loss: 0.4297\n",
      "[5/10] Step 240/675 - Loss: 0.4297\n",
      "[5/10] Step 250/675 - Loss: 0.2708\n",
      "[5/10] Step 250/675 - Loss: 0.2708\n",
      "[5/10] Step 260/675 - Loss: 0.7407\n",
      "[5/10] Step 260/675 - Loss: 0.7407\n",
      "[5/10] Step 270/675 - Loss: 0.6385\n",
      "[5/10] Step 270/675 - Loss: 0.6385\n",
      "[5/10] Step 280/675 - Loss: 0.6289\n",
      "[5/10] Step 280/675 - Loss: 0.6289\n",
      "[5/10] Step 290/675 - Loss: 0.7564\n",
      "[5/10] Step 290/675 - Loss: 0.7564\n",
      "[5/10] Step 300/675 - Loss: 0.3362\n",
      "[5/10] Step 300/675 - Loss: 0.3362\n",
      "[5/10] Step 310/675 - Loss: 0.3891\n",
      "[5/10] Step 310/675 - Loss: 0.3891\n",
      "[5/10] Step 320/675 - Loss: 0.5793\n",
      "[5/10] Step 320/675 - Loss: 0.5793\n",
      "[5/10] Step 330/675 - Loss: 0.7510\n",
      "[5/10] Step 330/675 - Loss: 0.7510\n",
      "[5/10] Step 340/675 - Loss: 0.5575\n",
      "[5/10] Step 340/675 - Loss: 0.5575\n",
      "[5/10] Step 350/675 - Loss: 0.5961\n",
      "[5/10] Step 350/675 - Loss: 0.5961\n",
      "[5/10] Step 360/675 - Loss: 0.5292\n",
      "[5/10] Step 360/675 - Loss: 0.5292\n",
      "[5/10] Step 370/675 - Loss: 0.3658\n",
      "[5/10] Step 370/675 - Loss: 0.3658\n",
      "[5/10] Step 380/675 - Loss: 0.5786\n",
      "[5/10] Step 380/675 - Loss: 0.5786\n",
      "[5/10] Step 390/675 - Loss: 0.6228\n",
      "[5/10] Step 390/675 - Loss: 0.6228\n",
      "[5/10] Step 400/675 - Loss: 0.5956\n",
      "[5/10] Step 400/675 - Loss: 0.5956\n",
      "[5/10] Step 410/675 - Loss: 0.5863\n",
      "[5/10] Step 410/675 - Loss: 0.5863\n",
      "[5/10] Step 420/675 - Loss: 0.4925\n",
      "[5/10] Step 420/675 - Loss: 0.4925\n",
      "[5/10] Step 430/675 - Loss: 0.5165\n",
      "[5/10] Step 430/675 - Loss: 0.5165\n",
      "[5/10] Step 440/675 - Loss: 0.6721\n",
      "[5/10] Step 440/675 - Loss: 0.6721\n",
      "[5/10] Step 450/675 - Loss: 0.4771\n",
      "[5/10] Step 450/675 - Loss: 0.4771\n",
      "[5/10] Step 460/675 - Loss: 0.7436\n",
      "[5/10] Step 460/675 - Loss: 0.7436\n",
      "[5/10] Step 470/675 - Loss: 0.7222\n",
      "[5/10] Step 470/675 - Loss: 0.7222\n",
      "[5/10] Step 480/675 - Loss: 0.5588\n",
      "[5/10] Step 480/675 - Loss: 0.5588\n",
      "[5/10] Step 490/675 - Loss: 0.3372\n",
      "[5/10] Step 490/675 - Loss: 0.3372\n",
      "[5/10] Step 500/675 - Loss: 0.4684\n",
      "[5/10] Step 500/675 - Loss: 0.4684\n",
      "[5/10] Step 510/675 - Loss: 0.7378\n",
      "[5/10] Step 510/675 - Loss: 0.7378\n",
      "[5/10] Step 520/675 - Loss: 0.3854\n",
      "[5/10] Step 520/675 - Loss: 0.3854\n",
      "[5/10] Step 530/675 - Loss: 0.2435\n",
      "[5/10] Step 530/675 - Loss: 0.2435\n",
      "[5/10] Step 540/675 - Loss: 0.5325\n",
      "[5/10] Step 540/675 - Loss: 0.5325\n",
      "[5/10] Step 550/675 - Loss: 0.4859\n",
      "[5/10] Step 550/675 - Loss: 0.4859\n",
      "[5/10] Step 560/675 - Loss: 0.7783\n",
      "[5/10] Step 560/675 - Loss: 0.7783\n",
      "[5/10] Step 570/675 - Loss: 0.6299\n",
      "[5/10] Step 570/675 - Loss: 0.6299\n",
      "[5/10] Step 580/675 - Loss: 0.8060\n",
      "[5/10] Step 580/675 - Loss: 0.8060\n",
      "[5/10] Step 590/675 - Loss: 0.5199\n",
      "[5/10] Step 590/675 - Loss: 0.5199\n",
      "[5/10] Step 600/675 - Loss: 0.7611\n",
      "[5/10] Step 600/675 - Loss: 0.7611\n",
      "[5/10] Step 610/675 - Loss: 0.4342\n",
      "[5/10] Step 610/675 - Loss: 0.4342\n",
      "[5/10] Step 620/675 - Loss: 0.5850\n",
      "[5/10] Step 620/675 - Loss: 0.5850\n",
      "[5/10] Step 630/675 - Loss: 0.3280\n",
      "[5/10] Step 630/675 - Loss: 0.3280\n",
      "[5/10] Step 640/675 - Loss: 0.7202\n",
      "[5/10] Step 640/675 - Loss: 0.7202\n",
      "[5/10] Step 650/675 - Loss: 0.5205\n",
      "[5/10] Step 650/675 - Loss: 0.5205\n",
      "[5/10] Step 660/675 - Loss: 0.5599\n",
      "[5/10] Step 660/675 - Loss: 0.5599\n",
      "[5/10] Step 670/675 - Loss: 0.6941\n",
      "[5/10] Step 670/675 - Loss: 0.6941\n",
      "[5/10] Step 675/675 - Loss: 0.6581\n",
      "[5/10] Step 675/675 - Loss: 0.6581\n",
      "Época 5 finalizada | Loss: 0.5859 | Acc: 79.46% | Tiempo: 129.3s\n",
      "Época 5 finalizada | Loss: 0.5859 | Acc: 79.46% | Tiempo: 129.3s\n",
      "Validación - Acc: 80.69%\n",
      "------------------------------------------------------------\n",
      "Sin mejora en validación (1/3)\n",
      "Validación - Acc: 80.69%\n",
      "------------------------------------------------------------\n",
      "Sin mejora en validación (1/3)\n",
      "[6/10] Step 10/675 - Loss: 0.6683\n",
      "[6/10] Step 10/675 - Loss: 0.6683\n",
      "[6/10] Step 20/675 - Loss: 0.8764\n",
      "[6/10] Step 20/675 - Loss: 0.8764\n",
      "[6/10] Step 30/675 - Loss: 0.6007\n",
      "[6/10] Step 30/675 - Loss: 0.6007\n",
      "[6/10] Step 40/675 - Loss: 0.5669\n",
      "[6/10] Step 40/675 - Loss: 0.5669\n",
      "[6/10] Step 50/675 - Loss: 0.5051\n",
      "[6/10] Step 50/675 - Loss: 0.5051\n",
      "[6/10] Step 60/675 - Loss: 0.5540\n",
      "[6/10] Step 60/675 - Loss: 0.5540\n",
      "[6/10] Step 70/675 - Loss: 0.8227\n",
      "[6/10] Step 70/675 - Loss: 0.8227\n",
      "[6/10] Step 80/675 - Loss: 0.5308\n",
      "[6/10] Step 80/675 - Loss: 0.5308\n",
      "[6/10] Step 90/675 - Loss: 0.7769\n",
      "[6/10] Step 90/675 - Loss: 0.7769\n",
      "[6/10] Step 100/675 - Loss: 0.5749\n",
      "[6/10] Step 100/675 - Loss: 0.5749\n",
      "[6/10] Step 110/675 - Loss: 0.5409\n",
      "[6/10] Step 110/675 - Loss: 0.5409\n",
      "[6/10] Step 120/675 - Loss: 0.7039\n",
      "[6/10] Step 120/675 - Loss: 0.7039\n",
      "[6/10] Step 130/675 - Loss: 0.7006\n",
      "[6/10] Step 130/675 - Loss: 0.7006\n",
      "[6/10] Step 140/675 - Loss: 0.5070\n",
      "[6/10] Step 140/675 - Loss: 0.5070\n",
      "[6/10] Step 150/675 - Loss: 0.5245\n",
      "[6/10] Step 150/675 - Loss: 0.5245\n",
      "[6/10] Step 160/675 - Loss: 0.5191\n",
      "[6/10] Step 160/675 - Loss: 0.5191\n",
      "[6/10] Step 170/675 - Loss: 0.7343\n",
      "[6/10] Step 170/675 - Loss: 0.7343\n",
      "[6/10] Step 180/675 - Loss: 0.6980\n",
      "[6/10] Step 180/675 - Loss: 0.6980\n",
      "[6/10] Step 190/675 - Loss: 0.5272\n",
      "[6/10] Step 190/675 - Loss: 0.5272\n",
      "[6/10] Step 200/675 - Loss: 0.5971\n",
      "[6/10] Step 200/675 - Loss: 0.5971\n",
      "[6/10] Step 210/675 - Loss: 0.3463\n",
      "[6/10] Step 210/675 - Loss: 0.3463\n",
      "[6/10] Step 220/675 - Loss: 0.3184\n",
      "[6/10] Step 220/675 - Loss: 0.3184\n",
      "[6/10] Step 230/675 - Loss: 0.2342\n",
      "[6/10] Step 230/675 - Loss: 0.2342\n",
      "[6/10] Step 240/675 - Loss: 0.7870\n",
      "[6/10] Step 240/675 - Loss: 0.7870\n",
      "[6/10] Step 250/675 - Loss: 0.6322\n",
      "[6/10] Step 250/675 - Loss: 0.6322\n",
      "[6/10] Step 260/675 - Loss: 0.6313\n",
      "[6/10] Step 260/675 - Loss: 0.6313\n",
      "[6/10] Step 270/675 - Loss: 0.5430\n",
      "[6/10] Step 270/675 - Loss: 0.5430\n",
      "[6/10] Step 280/675 - Loss: 0.5377\n",
      "[6/10] Step 280/675 - Loss: 0.5377\n",
      "[6/10] Step 290/675 - Loss: 0.4505\n",
      "[6/10] Step 290/675 - Loss: 0.4505\n",
      "[6/10] Step 300/675 - Loss: 0.4240\n",
      "[6/10] Step 300/675 - Loss: 0.4240\n",
      "[6/10] Step 310/675 - Loss: 0.4949\n",
      "[6/10] Step 310/675 - Loss: 0.4949\n",
      "[6/10] Step 320/675 - Loss: 0.6451\n",
      "[6/10] Step 320/675 - Loss: 0.6451\n",
      "[6/10] Step 330/675 - Loss: 0.6824\n",
      "[6/10] Step 330/675 - Loss: 0.6824\n",
      "[6/10] Step 340/675 - Loss: 0.4788\n",
      "[6/10] Step 340/675 - Loss: 0.4788\n",
      "[6/10] Step 350/675 - Loss: 0.6007\n",
      "[6/10] Step 350/675 - Loss: 0.6007\n",
      "[6/10] Step 360/675 - Loss: 0.7709\n",
      "[6/10] Step 360/675 - Loss: 0.7709\n",
      "[6/10] Step 370/675 - Loss: 0.4536\n",
      "[6/10] Step 370/675 - Loss: 0.4536\n",
      "[6/10] Step 380/675 - Loss: 0.5613\n",
      "[6/10] Step 380/675 - Loss: 0.5613\n",
      "[6/10] Step 390/675 - Loss: 0.4712\n",
      "[6/10] Step 390/675 - Loss: 0.4712\n",
      "[6/10] Step 400/675 - Loss: 0.5149\n",
      "[6/10] Step 400/675 - Loss: 0.5149\n",
      "[6/10] Step 410/675 - Loss: 0.3396\n",
      "[6/10] Step 410/675 - Loss: 0.3396\n",
      "[6/10] Step 420/675 - Loss: 0.5375\n",
      "[6/10] Step 420/675 - Loss: 0.5375\n",
      "[6/10] Step 430/675 - Loss: 0.5285\n",
      "[6/10] Step 430/675 - Loss: 0.5285\n",
      "[6/10] Step 440/675 - Loss: 0.9233\n",
      "[6/10] Step 440/675 - Loss: 0.9233\n",
      "[6/10] Step 450/675 - Loss: 0.5900\n",
      "[6/10] Step 450/675 - Loss: 0.5900\n",
      "[6/10] Step 460/675 - Loss: 0.8031\n",
      "[6/10] Step 460/675 - Loss: 0.8031\n",
      "[6/10] Step 470/675 - Loss: 0.5407\n",
      "[6/10] Step 470/675 - Loss: 0.5407\n",
      "[6/10] Step 480/675 - Loss: 0.6702\n",
      "[6/10] Step 480/675 - Loss: 0.6702\n",
      "[6/10] Step 490/675 - Loss: 0.3495\n",
      "[6/10] Step 490/675 - Loss: 0.3495\n",
      "[6/10] Step 500/675 - Loss: 0.7445\n",
      "[6/10] Step 500/675 - Loss: 0.7445\n",
      "[6/10] Step 510/675 - Loss: 0.5962\n",
      "[6/10] Step 510/675 - Loss: 0.5962\n",
      "[6/10] Step 520/675 - Loss: 0.4688\n",
      "[6/10] Step 520/675 - Loss: 0.4688\n",
      "[6/10] Step 530/675 - Loss: 0.5497\n",
      "[6/10] Step 530/675 - Loss: 0.5497\n",
      "[6/10] Step 540/675 - Loss: 0.5016\n",
      "[6/10] Step 540/675 - Loss: 0.5016\n",
      "[6/10] Step 550/675 - Loss: 0.4512\n",
      "[6/10] Step 550/675 - Loss: 0.4512\n",
      "[6/10] Step 560/675 - Loss: 0.4441\n",
      "[6/10] Step 560/675 - Loss: 0.4441\n",
      "[6/10] Step 570/675 - Loss: 0.4138\n",
      "[6/10] Step 570/675 - Loss: 0.4138\n",
      "[6/10] Step 580/675 - Loss: 0.5195\n",
      "[6/10] Step 580/675 - Loss: 0.5195\n",
      "[6/10] Step 590/675 - Loss: 0.3755\n",
      "[6/10] Step 590/675 - Loss: 0.3755\n",
      "[6/10] Step 600/675 - Loss: 0.6417\n",
      "[6/10] Step 600/675 - Loss: 0.6417\n",
      "[6/10] Step 610/675 - Loss: 0.6026\n",
      "[6/10] Step 610/675 - Loss: 0.6026\n",
      "[6/10] Step 620/675 - Loss: 0.3849\n",
      "[6/10] Step 620/675 - Loss: 0.3849\n",
      "[6/10] Step 630/675 - Loss: 0.5622\n",
      "[6/10] Step 630/675 - Loss: 0.5622\n",
      "[6/10] Step 640/675 - Loss: 0.5982\n",
      "[6/10] Step 640/675 - Loss: 0.5982\n",
      "[6/10] Step 650/675 - Loss: 0.5495\n",
      "[6/10] Step 650/675 - Loss: 0.5495\n",
      "[6/10] Step 660/675 - Loss: 0.5223\n",
      "[6/10] Step 660/675 - Loss: 0.5223\n",
      "[6/10] Step 670/675 - Loss: 0.5117\n",
      "[6/10] Step 670/675 - Loss: 0.5117\n",
      "[6/10] Step 675/675 - Loss: 0.6816\n",
      "[6/10] Step 675/675 - Loss: 0.6816\n",
      "Época 6 finalizada | Loss: 0.5686 | Acc: 79.94% | Tiempo: 129.3s\n",
      "Época 6 finalizada | Loss: 0.5686 | Acc: 79.94% | Tiempo: 129.3s\n",
      "Validación - Acc: 80.33%\n",
      "------------------------------------------------------------\n",
      "Sin mejora en validación (2/3)\n",
      "Validación - Acc: 80.33%\n",
      "------------------------------------------------------------\n",
      "Sin mejora en validación (2/3)\n",
      "[7/10] Step 10/675 - Loss: 0.5863\n",
      "[7/10] Step 10/675 - Loss: 0.5863\n",
      "[7/10] Step 20/675 - Loss: 0.5050\n",
      "[7/10] Step 20/675 - Loss: 0.5050\n",
      "[7/10] Step 30/675 - Loss: 0.8096\n",
      "[7/10] Step 30/675 - Loss: 0.8096\n",
      "[7/10] Step 40/675 - Loss: 0.3976\n",
      "[7/10] Step 40/675 - Loss: 0.3976\n",
      "[7/10] Step 50/675 - Loss: 0.6350\n",
      "[7/10] Step 50/675 - Loss: 0.6350\n",
      "[7/10] Step 60/675 - Loss: 0.4942\n",
      "[7/10] Step 60/675 - Loss: 0.4942\n",
      "[7/10] Step 70/675 - Loss: 0.5877\n",
      "[7/10] Step 70/675 - Loss: 0.5877\n",
      "[7/10] Step 80/675 - Loss: 0.2986\n",
      "[7/10] Step 80/675 - Loss: 0.2986\n",
      "[7/10] Step 90/675 - Loss: 0.3427\n",
      "[7/10] Step 90/675 - Loss: 0.3427\n",
      "[7/10] Step 100/675 - Loss: 0.2470\n",
      "[7/10] Step 100/675 - Loss: 0.2470\n",
      "[7/10] Step 110/675 - Loss: 0.8288\n",
      "[7/10] Step 110/675 - Loss: 0.8288\n",
      "[7/10] Step 120/675 - Loss: 0.6126\n",
      "[7/10] Step 120/675 - Loss: 0.6126\n",
      "[7/10] Step 130/675 - Loss: 0.5592\n",
      "[7/10] Step 130/675 - Loss: 0.5592\n",
      "[7/10] Step 140/675 - Loss: 0.5100\n",
      "[7/10] Step 140/675 - Loss: 0.5100\n",
      "[7/10] Step 150/675 - Loss: 0.8393\n",
      "[7/10] Step 150/675 - Loss: 0.8393\n",
      "[7/10] Step 160/675 - Loss: 0.4336\n",
      "[7/10] Step 160/675 - Loss: 0.4336\n",
      "[7/10] Step 170/675 - Loss: 0.6992\n",
      "[7/10] Step 170/675 - Loss: 0.6992\n",
      "[7/10] Step 180/675 - Loss: 0.4218\n",
      "[7/10] Step 180/675 - Loss: 0.4218\n",
      "[7/10] Step 190/675 - Loss: 0.1892\n",
      "[7/10] Step 190/675 - Loss: 0.1892\n",
      "[7/10] Step 200/675 - Loss: 0.3327\n",
      "[7/10] Step 200/675 - Loss: 0.3327\n",
      "[7/10] Step 210/675 - Loss: 0.4561\n",
      "[7/10] Step 210/675 - Loss: 0.4561\n",
      "[7/10] Step 220/675 - Loss: 0.4425\n",
      "[7/10] Step 220/675 - Loss: 0.4425\n",
      "[7/10] Step 230/675 - Loss: 0.3027\n",
      "[7/10] Step 230/675 - Loss: 0.3027\n",
      "[7/10] Step 240/675 - Loss: 0.5255\n",
      "[7/10] Step 240/675 - Loss: 0.5255\n",
      "[7/10] Step 250/675 - Loss: 0.6202\n",
      "[7/10] Step 250/675 - Loss: 0.6202\n",
      "[7/10] Step 260/675 - Loss: 0.7462\n",
      "[7/10] Step 260/675 - Loss: 0.7462\n",
      "[7/10] Step 270/675 - Loss: 0.4914\n",
      "[7/10] Step 270/675 - Loss: 0.4914\n",
      "[7/10] Step 280/675 - Loss: 0.6436\n",
      "[7/10] Step 280/675 - Loss: 0.6436\n",
      "[7/10] Step 290/675 - Loss: 0.5725\n",
      "[7/10] Step 290/675 - Loss: 0.5725\n",
      "[7/10] Step 300/675 - Loss: 1.1110\n",
      "[7/10] Step 300/675 - Loss: 1.1110\n",
      "[7/10] Step 310/675 - Loss: 0.6538\n",
      "[7/10] Step 310/675 - Loss: 0.6538\n",
      "[7/10] Step 320/675 - Loss: 0.6947\n",
      "[7/10] Step 320/675 - Loss: 0.6947\n",
      "[7/10] Step 330/675 - Loss: 0.5314\n",
      "[7/10] Step 330/675 - Loss: 0.5314\n",
      "[7/10] Step 340/675 - Loss: 0.5771\n",
      "[7/10] Step 340/675 - Loss: 0.5771\n",
      "[7/10] Step 350/675 - Loss: 0.5040\n",
      "[7/10] Step 350/675 - Loss: 0.5040\n",
      "[7/10] Step 360/675 - Loss: 0.9382\n",
      "[7/10] Step 360/675 - Loss: 0.9382\n",
      "[7/10] Step 370/675 - Loss: 0.4345\n",
      "[7/10] Step 370/675 - Loss: 0.4345\n",
      "[7/10] Step 380/675 - Loss: 0.4152\n",
      "[7/10] Step 380/675 - Loss: 0.4152\n",
      "[7/10] Step 390/675 - Loss: 0.7197\n",
      "[7/10] Step 390/675 - Loss: 0.7197\n",
      "[7/10] Step 400/675 - Loss: 0.4598\n",
      "[7/10] Step 400/675 - Loss: 0.4598\n",
      "[7/10] Step 410/675 - Loss: 0.3407\n",
      "[7/10] Step 410/675 - Loss: 0.3407\n",
      "[7/10] Step 420/675 - Loss: 0.4362\n",
      "[7/10] Step 420/675 - Loss: 0.4362\n",
      "[7/10] Step 430/675 - Loss: 0.7071\n",
      "[7/10] Step 430/675 - Loss: 0.7071\n",
      "[7/10] Step 440/675 - Loss: 0.5638\n",
      "[7/10] Step 440/675 - Loss: 0.5638\n",
      "[7/10] Step 450/675 - Loss: 0.3952\n",
      "[7/10] Step 450/675 - Loss: 0.3952\n",
      "[7/10] Step 460/675 - Loss: 0.2888\n",
      "[7/10] Step 460/675 - Loss: 0.2888\n",
      "[7/10] Step 470/675 - Loss: 0.5690\n",
      "[7/10] Step 470/675 - Loss: 0.5690\n",
      "[7/10] Step 480/675 - Loss: 0.6147\n",
      "[7/10] Step 480/675 - Loss: 0.6147\n",
      "[7/10] Step 490/675 - Loss: 0.4688\n",
      "[7/10] Step 490/675 - Loss: 0.4688\n",
      "[7/10] Step 500/675 - Loss: 0.3740\n",
      "[7/10] Step 500/675 - Loss: 0.3740\n",
      "[7/10] Step 510/675 - Loss: 0.6608\n",
      "[7/10] Step 510/675 - Loss: 0.6608\n",
      "[7/10] Step 520/675 - Loss: 0.2288\n",
      "[7/10] Step 520/675 - Loss: 0.2288\n",
      "[7/10] Step 530/675 - Loss: 0.3852\n",
      "[7/10] Step 530/675 - Loss: 0.3852\n",
      "[7/10] Step 540/675 - Loss: 0.5962\n",
      "[7/10] Step 540/675 - Loss: 0.5962\n",
      "[7/10] Step 550/675 - Loss: 0.5567\n",
      "[7/10] Step 550/675 - Loss: 0.5567\n",
      "[7/10] Step 560/675 - Loss: 0.3854\n",
      "[7/10] Step 560/675 - Loss: 0.3854\n",
      "[7/10] Step 570/675 - Loss: 0.3414\n",
      "[7/10] Step 570/675 - Loss: 0.3414\n",
      "[7/10] Step 580/675 - Loss: 0.4253\n",
      "[7/10] Step 580/675 - Loss: 0.4253\n",
      "[7/10] Step 590/675 - Loss: 0.6893\n",
      "[7/10] Step 590/675 - Loss: 0.6893\n",
      "[7/10] Step 600/675 - Loss: 0.5733\n",
      "[7/10] Step 600/675 - Loss: 0.5733\n",
      "[7/10] Step 610/675 - Loss: 0.6058\n",
      "[7/10] Step 610/675 - Loss: 0.6058\n",
      "[7/10] Step 620/675 - Loss: 0.3462\n",
      "[7/10] Step 620/675 - Loss: 0.3462\n",
      "[7/10] Step 630/675 - Loss: 0.2849\n",
      "[7/10] Step 630/675 - Loss: 0.2849\n",
      "[7/10] Step 640/675 - Loss: 0.3390\n",
      "[7/10] Step 640/675 - Loss: 0.3390\n",
      "[7/10] Step 650/675 - Loss: 0.2523\n",
      "[7/10] Step 650/675 - Loss: 0.2523\n",
      "[7/10] Step 660/675 - Loss: 0.8568\n",
      "[7/10] Step 660/675 - Loss: 0.8568\n",
      "[7/10] Step 670/675 - Loss: 0.4154\n",
      "[7/10] Step 670/675 - Loss: 0.4154\n",
      "[7/10] Step 675/675 - Loss: 0.5619\n",
      "[7/10] Step 675/675 - Loss: 0.5619\n",
      "Época 7 finalizada | Loss: 0.5623 | Acc: 80.39% | Tiempo: 129.2s\n",
      "Época 7 finalizada | Loss: 0.5623 | Acc: 80.39% | Tiempo: 129.2s\n",
      "Validación - Acc: 81.70%\n",
      "------------------------------------------------------------\n",
      "Sin mejora en validación (3/3)\n",
      "Early stopping activado.\n",
      "Validación - Acc: 81.70%\n",
      "------------------------------------------------------------\n",
      "Sin mejora en validación (3/3)\n",
      "Early stopping activado.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuración\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "num_epochs = 10\n",
    "patience = 3\n",
    "\n",
    "# Early Stopping y listas para guardar métricas\n",
    "best_val_acc = 0.0\n",
    "epochs_without_improvement = 0\n",
    "best_model_path = \"mejor_modelo.pth\"\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        if (i+1) % 10 == 0 or (i+1) == len(train_loader):\n",
    "            print(f\"[{epoch+1}/{num_epochs}] Step {i+1}/{len(train_loader)} - Loss: {loss.item():.4f}\", flush=True)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accs.append(epoch_acc)\n",
    "\n",
    "    print(f\"Época {epoch+1} finalizada | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}% | Tiempo: {duration:.1f}s\", flush=True)\n",
    "\n",
    "    # === Validación ===\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_targets in val_loader:\n",
    "            val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            _, val_predicted = val_outputs.max(1)\n",
    "            val_total += val_targets.size(0)\n",
    "            val_correct += val_predicted.eq(val_targets).sum().item()\n",
    "\n",
    "    val_acc = 100. * val_correct / val_total\n",
    "    val_accs.append(val_acc)\n",
    "    print(f\"Validación - Acc: {val_acc:.2f}%\\n{'-'*60}\", flush=True)\n",
    "\n",
    "    # === Early stopping ===\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Nuevo mejor modelo guardado con Acc: {best_val_acc:.2f}%\", flush=True)\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Sin mejora en validación ({epochs_without_improvement}/{patience})\", flush=True)\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"Early stopping activado.\")\n",
    "            break\n",
    "\n",
    "# === Graficar ===\n",
    "epochs_range = range(1, len(train_losses)+1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_range, train_losses, label='Train Loss')\n",
    "plt.plot(epochs_range, train_accs, label='Train Acc')\n",
    "plt.plot(epochs_range, val_accs, label='Val Acc')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Curvas de entrenamiento y validación')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Paso 2: Configurar hiperparámetros\n",
    "batch_size = 128\n",
    "learning_rate = 5e-5\n",
    "num_epochs = 50\n",
    "patience = 5\n",
    "\n",
    "# Paso 3: Data augmentation y normalización\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Paso 4: Dataset y dataloader\n",
    "dataset = datasets.ImageFolder('path_a_eurosat', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Paso 5: Modelo (vit_b_rvsa)\n",
    "from MTP.Multi_Task_Pretrain.backbone.vit_win_rvsa_v3_wsz7 import vit_b_rvsa\n",
    "model = vit_b_rvsa()\n",
    "model.head = nn.Linear(model.head.in_features, 10)\n",
    "model = model.cuda()\n",
    "\n",
    "# Paso 6: Definir pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# Paso 7: Early stopping y entrenamiento\n",
    "early_stop_counter = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "# Generar nombre único para guardar el modelo\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "best_model_path1 = f'best_model_{timestamp}.pth'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"[Epoch {epoch+1}/{num_epochs}] Step {i}/{len(dataloader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    scheduler.step()\n",
    "\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accs.append(acc)\n",
    "\n",
    "    val_acc = acc  # Validación simplificada\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} finished | Loss: {avg_loss:.4f} | Acc: {acc:.2f}% | Time: {time.time()-start_time:.1f}s\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path1)\n",
    "        print(f\"New best model saved with Acc: {val_acc:.2f}% -> {best_model_path1}\")\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter +=1\n",
    "        print(f\"No improvement in validation ({early_stop_counter}/{patience})\")\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping activated.\")\n",
    "            break\n",
    "\n",
    "# Paso 8: Graficar resultados\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(train_accs)+1), train_accs, label='Training Acc')\n",
    "plt.plot(range(1, len(val_accs)+1), val_accs, label='Validation Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric')\n",
    "plt.title('Training and Validation Metrics')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(f'training_plot_{timestamp}.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
